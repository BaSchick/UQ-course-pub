{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c69265",
   "metadata": {},
   "source": [
    "# Outliers\n",
    "\n",
    "*SG2227 Saleh Rezaeiravesh and Philipp Schlatter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19337276",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "import math as mt\n",
    "from scipy import special\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2,t,norm\n",
    "\n",
    "π = mt.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be49a44",
   "metadata": {},
   "source": [
    "We show here the method based on *Chauvenet's criteron* as one way to identify an outlier in a series of data. It goes back to William Chauvenet (24 May 1820 in Milford, Pennsylvania – 13 December 1870 in St. Paul, Minnesota), who was mainly working in the US Navy.\n",
    "\n",
    "The basic idea is that one defines a band with acceptable values around the mean of the data set. The width of this band depends both on the variance (or its estimator), but also the number of samples in the series. The more samples you have, the more spread you allow.\n",
    "\n",
    "Assuming a normal distribution, valid points points should be close to the mean with probability $P=1-1/(2N)=(N-1)/N$. Using the normalised Gaussian variable $z=(x-\\mu)/\\sigma)$, this translates to\n",
    "\n",
    "$$P(-z_\\alpha \\leq z \\leq z_\\alpha) = \\alpha = \\frac{1}{\\sqrt{2\\pi}}\\int_{-z_\\alpha}^{z_\\alpha} \\exp\\left(-\\frac{u^2}{2}\\right) \\mathrm d u $$\n",
    "\n",
    "with $\\alpha = 1-1/(2N)$. The valid points are then in the interval\n",
    "\n",
    "$$x\\in [\\overline{x}-z_\\alpha s_x, \\overline{x}+z_\\alpha s_x ] \\ .$$\n",
    "\n",
    "The relevant values for $z_\\alpha$ for a few $N$ are listed in the table below. For instance for a sample with 10 points, the probability to be close to the mean is $95\\%$, so one requires that a valid point must be in the region where $95\\%$ of the points of the populations lie. For $N=1000$, this probability has increased to $99.95\\%$. So the more points one has, the more forgiving one may be, as the estimated parameters ($\\hat{\\mu}$, $\\hat{\\sigma}$) are less affected by the points far from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7960d177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3     1.3829941271006387     0.8333333333333334\n",
      "4     1.5341205443525465     0.875\n",
      "5     1.6448536269514724     0.9\n",
      "6     1.731664396122245     0.9166666666666666\n",
      "10     1.9599639845400545     0.95\n",
      "20     2.2414027276049473     0.975\n",
      "50     2.575829303548901     0.99\n",
      "100     2.8070337683438114     0.995\n",
      "200     3.0233414397391543     0.9975\n",
      "500     3.2905267314919255     0.999\n",
      "1000     3.4807564043462422     0.9995\n"
     ]
    }
   ],
   "source": [
    "Nlist=(3,4,5,6,10,20,50,100,200,500,1000)\n",
    "for N in Nlist:\n",
    "    α = 1-1/(2*N)\n",
    "    print(N,'   ',np.sqrt(2)*special.erfinv(α),'   ',α)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c18b3dd",
   "metadata": {},
   "source": [
    "Typically, one applies the Chavenet's criterion just once, but it can also be done iteratively, to detect what is called *shielded outliers*, that only become apparent once other stronger outliers are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c95783a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.77, 0.3012474066278416)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T=np.array([24.67,24.75,25.02,24.70,24.83,24.08,25.11,25.00])\n",
    "np.mean(T),np.std(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c23bb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier:  24.08\n"
     ]
    }
   ],
   "source": [
    "N=T.size\n",
    "α = 1-1/(2*N)\n",
    "z_α=np.sqrt(2)*special.erfinv(α)\n",
    "d=z_α*np.std(T)\n",
    "m=np.mean(T)\n",
    "TT=np.array([])\n",
    "for i in range(N):\n",
    "    if (T[i]>(m+d) or T[i]<(m-d)):\n",
    "        print('Outlier: ',T[i])\n",
    "    else:\n",
    "        TT=np.append(TT,T[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78ffdee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.868571428571425, 0.16119452059356004)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(TT),np.std(TT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15597b0",
   "metadata": {},
   "source": [
    "Minute change of the mean, however a significant reduction of the standard deviation by a factor of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492bcb54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
